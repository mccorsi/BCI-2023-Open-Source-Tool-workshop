# W5 - Offline and online tools for real-world BCI applications![Uploading image.png…]()


[2023 International BCI meeting](https://bcisociety.org/bci-meeting/)


Workshop W5 Session 1 - Wednesday, June 7, 9:30am – 12:30pm (Sonian Forest Time) - room Amarante

## Organizers:
- [Sylvain Chevallier](https://sylvchev.github.io/): Full Professor, University Paris-Saclay, A&O team, France 
- [Pierre Clisson](https://clisson.com/): Independent Scientist
- [Arthur Desbois](https://www.linkedin.com/in/arthur-desbois-801a9313a/?originalSubdomain=fr): Research Engineer, Inria Paris, Aramis project-team, Paris Brain Institute
- [Pedro L. C. Rodrigues](https://plcrodrigues.github.io/): Research Scientist, Inria Grenoble, Statify project-team, France
- [Marie-Constance Corsi](https://marieconstance-corsi.netlify.app/): Inria Research Scientist, Inria Paris, Aramis project-team, Paris Brain Institute


## Q&A
Here is a document that gathers all the questions and their answer at the workshop following this link. Moreover, you can directly comment the document if you want to ask more questions and add precisions.

Q&A link: https://tinyurl.com/4nbrbtbh


## Abstract
The ecosystem of open source tools for brain signal analysis has greatly matured in recent years and has been essential in many instances of modern research. In this workshop, we will show to which extent the BCI community can benefit from open science practices. We will notably present four tools for developing new experimental setups, doing feature selection for classification tasks, and favoring reproducibility and replicability. 
During the first part, participants will receive hands-on instructions on how to extract and select features from EEG signals with HappyFeat and how to pre-process and classify them with pyRiemann.
The second part will focus on online BCIs: attendees will learn the core concepts driving Timeflux, how to describe processing pipelines, how to create interfaces, and how to easily develop their own plugins. They will also discover how to synchronize EEG data and stimuli without any complicated or expensive setup. In the third and final part, participants will learn how to evaluate ERP classification methods via approaches that favor reproducibility and replicability with MOABB.
Lastly, during a general discussion panel, attendees will discuss ways to use these tools for their own research and how to contribute to the development of these open source tools. 


## Intended audience
Anyone interested in practical BCIs: neuroscientists, research engineers, developers. Programming or data science skills are great but not required for this workshop.

## Learning objectives
-	identifying at least 1 tool suitable for their own research
-	identifying at least 3 do and don'ts when using open source tools for BCI
-	identifying at least 1 way to contribute to the development of open source tools 

## Expected output(s)
-	A github repository with all the resources (notebooks, code and demos) presented during the workshop
-	A Q&A document that gathers all the questions asked by the audience during the workshop will be available online.
-	New contributors to the open source packages presented during the workshop.


## Timetable

### Welcome & opening remarks

### Part 1, Favoring reproducibility and replicability when conceiving new offline BCI pipelines
*Who's who? Benchmarking EEG pipelines in BCI with MOABB*, by S. Chevallier (20' talk + 5' Q&A)

### Part 2, Developing blocks of the BCI experiments
*A guided tour on Riemannian methods for BCI via pyRiemann*, by P.L.C. Rodrigues (20' talk + 5' Q&A)

*High-speed train(ing): An efficient trial-and-error oriented framework for feature selection in BCI, with HappyFeat*, by A. Desbois (20' talk + 5' Q&A)

### Part 3, Developing new experimental setups
*Online BCIs with Timeflux*, by P. Clisson (10' talk)

*Commented use case: a cVEP BCI*, by P. Clisson (10' demo + 5' Q&A)

### Part 4, Discussions
Practical discussion on participants use cases based on the Q&A document.

### Conclusion & closing remarks

## Resources

## References
